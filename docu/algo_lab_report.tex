\documentclass[11pt]{amsart}
\usepackage{geometry}                
\geometry{letterpaper}                  
\usepackage[parfill]{parskip}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{epstopdf}
\usepackage{csquotes}
\DeclareGraphicsRule{.tif}{png}{.png}{`convert #1 `dirname #1`/`basename #1 .tif`.png}

\usepackage{tikz}
\usetikzlibrary{chains,fit,shapes}
\usepackage{hyperref}

\usepackage{algorithm}
\usepackage{algpseudocode}
\algnewcommand\algorithmicto{\textbf{to}}
\algnewcommand\algorithmicFalse{\textbf{true}}
\algnewcommand\algorithmicTrue{\textbf{true}}

\usepackage{color}
\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}

%%%%%%%%
% Draw functions
\newcommand{\minsearchExample}[4] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {7};
                			\node [on chain=1,tmtape] (second) {5};
                			\node [on chain=1,tmtape] (third) {10};
                			\node [on chain=1,tmtape] (fourth) {1};
               			\node [on chain=1,tmtape] (fifth) {9};
                			\node [on chain=1,tmtape] (sixth) {-1};
			        \node [on chain=1,tmtape] (seventh) {-2};
			        \node [on chain=1,tmtape] (eighth) {12};
			        \node [on chain=1,tmtape] (ninth) {1};
			        \node [on chain=1,tmtape] (tenth){6};
           		\end{scope}
			%% draw pointer and min box
			\node [tmhead,yshift=-.6cm] at (#2.south) (pointer) {$p$};
			\node[minbox, yshift=-1.3cm] at (#3.south) {$min=#4$};
            	\end{tikzpicture}
		\vspace{.5cm}	
}

\newcommand{\selectSortExample}[9] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {#2};
                			\node [on chain=1,tmtape] (second) {#3};
                			\node [on chain=1,tmtape] (third) {#4};
                			\node [on chain=1,tmtape] (fourth) {#5};
               			\node [on chain=1,tmtape] (fifth) {#6};
                			\node [on chain=1,tmtape] (sixth) {#7};
           		\end{scope}
			%% draw pointer and min box
			\node [tmhead,yshift=-.6cm] at (#8.south) (nMin) {$nMin=#9$};
            	\end{tikzpicture}
		\vspace{.5cm}	
}

\newcommand{\insertSortExample}[9] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {#2};
                			\node [on chain=1,tmtape] (second) {#3};
                			\node [on chain=1,tmtape] (third) {#4};
                			\node [on chain=1,tmtape] (fourth) {#5};
               			\node [on chain=1,tmtape] (fifth) {#6};
                			\node [on chain=1,tmtape] (sixth) {#7};
           		\end{scope}
			%% draw pointer and min box
			\node [tmhead,yshift=-.6cm] at (#8.south) (pointer) {$#9$};
            	\end{tikzpicture}
		\vspace{.5cm}	
}

\newcommand{\mergeExampleTmp}[9] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {#2};
                			\node [on chain=1,tmtape] (second) {#3};
                			\node [on chain=1,tmtape] (third) {#4};
                			\node [on chain=1,tmtape] (fourth) {#5};
               			\node [on chain=1,tmtape] (fifth) {#6};
                			\node [on chain=1,tmtape] (sixth) {#7};
           		\end{scope}
			%% draw pointer and min box
			\node [tmhead,yshift=-.6cm] at (#8.south) {$l$};
			\node[minbox, yshift=-1.3cm] at (#9.south) {$r$};
            	\end{tikzpicture}
		\vspace{.5cm}	
}

\newcommand{\mergeExampleSorted}[8] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {#2};
                			\node [on chain=1,tmtape] (second) {#3};
                			\node [on chain=1,tmtape] (third) {#4};
                			\node [on chain=1,tmtape] (fourth) {#5};
               			\node [on chain=1,tmtape] (fifth) {#6};
                			\node [on chain=1,tmtape] (sixth) {#7};
           		\end{scope}
			%% draw pointer and min box
			\node [tmhead,yshift=-.6cm] at (#8.south) {$i$};
            	\end{tikzpicture}
		\vspace{.5cm}	
}

\newcommand{\mergeSortsExample}[9] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {#2};
                			\node [on chain=1,tmtape] (second) {#3};
                			\node [on chain=1,tmtape] (third) {#4};
                			\node [on chain=1,tmtape] (fourth) {#5};
               			\node [on chain=1,tmtape] (fifth) {#6};
                			\node [on chain=1,tmtape] (sixth) {#7};
			        \node [on chain=1,tmtape] (eighth) {#8};
			        \node [on chain=1,tmtape] (ninth) {#9};
           		\end{scope}
            	\end{tikzpicture}
		\vspace{.5cm}	
}

\newcommand{\quicksortsExample}[9] {
		\begin{tikzpicture}
            		\tikzstyle{every path}=[very thick]
            
            		\edef\sizetape{0.7cm}
            		\tikzstyle{tmtape}=[draw,minimum size=\sizetape] 
			\tikzstyle{tmhead}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.25cm}]
			\tikzstyle{minbox}=[arrow box,draw,minimum size=.5cm,arrow box
arrows={north:.3cm}]      
            
            		%% draw data array
            		\begin{scope}[start chain=1 going right,node distance=-0.15mm]
				\node [on chain=1,tmtape, draw=none] {#1:};
                			\node [on chain=1,tmtape] (first) {#2};
                			\node [on chain=1,tmtape] (second) {#3};
                			\node [on chain=1,tmtape] (third) {#4};
                			\node [on chain=1,tmtape] (fourth) {#5};
               			\node [on chain=1,tmtape] (fifth) {#6};
                			\node [on chain=1,tmtape] (sixth) {#7};
			        \node [on chain=1,tmtape] (eighth) {#8};
			        	\node [on chain=1,tmtape] (ninth) {#9};
           		\end{scope}
            	\end{tikzpicture}
		\vspace{.5cm}	
}

%%%%%%%%
\begin{document}
\begin{titlepage}
	\centering
	\includegraphics[width=0.5\textwidth]{hska-logo}\par\vspace{1cm}
	{\scshape\LARGE University of Applied Sciences - Karlsruhe \par}
	\vspace{1cm}
	{\scshape\Large Report~-Algorithm~Laboratory\par}
	\vspace{1.5cm}
	{\huge\bfseries Comparison and optimization of Sorting Algorithms\par}
	\vspace{2cm}
	{\Large\itshape Manuel Vogel\par}
	\vfill
	supervised by\par
	Prof~Dr.~Christian \textsc{Pape}
	\vfill
	{\large \today\par}
\end{titlepage}
\section{Introduction}
Search algorithms are important in preprocessing of many other algorithms like image processing or displaying results in a determined order - ascending or descending.
The purpose of this laboratory exercise is to show the performance of the four algorithms 
\begin{enumerate}
	\item Sort via direct selection
		\begin{itemize}
			\item with optimal search of the minimum
			\item with non-optimal search of the minimum
		\end{itemize}
	\item Sort via direct insert
		\begin{itemize}
			\item with a watcher-element
			\item without a watcher-element
		\end{itemize}
	\item Mergesort
		\begin{itemize}
			\item natural
			\item bottom up
		\end{itemize}
	\item Quicksort
		\begin{itemize}
			\item 3-way-partitioning\footnote{\url{http://www.sorting-algorithms.com/static/QuicksortIsOptimal.pdf}}
			\item 3-way-partitioning with hybridization.
		\end{itemize}
\end{enumerate}
The goal is to point of the improvement of the performance of the algorithms in corner cases like an ascending sorted (best case), descending sorted (worst case) and randomly ordered floating point numbers. The implementation should also be able to deal with integers and strings. The programming language is C++.

First the algorithms will be described in detail with an added pseudocode, sketches and runtime behavior in the $O$-Notation. In the third section the setup of test environment - compiler with flags, IDE, language and test framework - will be described, containing the fixed preconditions of the tests and the execution with some code examples. The fourth section deals with the data of the time measuring and how it was realized. The fifth section shows the results of the measured performance of each algorithm. Everything will be summed up in the last and sixth chapter. 

%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Description of  the used algorithms}
%
% for each algorithm a short description, pseudocode and analysis in O-Notation
%
\subsection{Minimumsearch}
\begin{description}
	\item[Short Description] Searching for the minimum in data can be done by starting at two different points:
	\begin{enumerate}
		\item at the beginning of data
		\item at the end of the data.
	\end{enumerate}
	The first option is faster because the CPU can load the next chunk of the data in cache by prefetching. On the other hand the second option will cause a lot of cache-misses, because the expected data will not be in the cache. Hence the second option is slower. 
	\item[Pseudocode]: Optimal option 1) for $I := input~data$, $s := lower~bound$ and $e := upper~bound$:
	\begin{algorithm}
	\caption{Optimal minimum search}\label{opminsearch}
		\begin{algorithmic}[1]
		\Require $|I| \ge 1$
		\Statex
		\Procedure{OptimalMinSearch}{$I, s, e$}
			\If{$|I| = 1$} \State \Return $0$ \EndIf
			\State \State $minIdx \gets s$
			\For{$i \gets (s+1)~\algorithmicto~e$}
				\If{$I[i] < I[minIdx]$} \State $m \gets i$ \EndIf
			\EndFor
			\State \Return $minIdx$
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}	
	\vspace{4cm}
	\item[Example] for optimal \\[0.5cm]
		\begin{center}
			\minsearchExample{Start}{second}{first}{7}
			\minsearchExample{1st step}{third}{second}{5}
			\minsearchExample{2nd step}{fourth}{second}{5}	
			\minsearchExample{3rd step}{fifth}{fourth}{1}	
			\minsearchExample{4th step}{sixth}{fourth}{1}	
			\minsearchExample{5th step}{seventh}{sixth}{-1}
			\minsearchExample{6th step}{eighth}{seventh}{-2}
			\minsearchExample{5th step}{ninth}{seventh}{-2}	
			\minsearchExample{last step}{tenth}{seventh}{-2}			
		\end{center}
	\item[Pseudocode]: Non-optimal option 2) for $I := input~data$, $s := lower~bound$ and $e := upper~bound$:
	\begin{algorithm}
	\caption{Non-optimal minimum search}
		\begin{algorithmic}[1]
		\Require $|I| \ge 1$
		\Statex
		\Procedure{NonOptimalMinSearch}{$I, s, e$}
			\If{$|I| = 1$} \State \Return $0$ \EndIf
			\State \State $minIdx \gets (e-1)$
			\For{$i \gets (e-1)~\algorithmicto~s$}
				\If{$I[i] < I[minIdx]$} \State $m \gets i$ \EndIf
			\EndFor
			\State \Return $minIdx$
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\vspace{2cm}
	\item[Example] for non-optimal \\[0.5cm]
		\begin{center}
			\minsearchExample{Start}{ninth}{tenth}{6}
			\minsearchExample{1st step}{eighth}{ninth}{1}
			\minsearchExample{2nd step}{seventh}{ninth}{1}	
			\minsearchExample{3rd step}{sixth}{ninth}{1}	
			\minsearchExample{4th step}{fifth}{seventh}{-2}	
			\minsearchExample{5th step}{fourth}{seventh}{-2}
			\minsearchExample{6th step}{third}{seventh}{-2}
			\minsearchExample{5th step}{second}{seventh}{-2}	
			\minsearchExample{last step}{first}{seventh}{-2}		
	        \end{center}	
         \end{description}

\newpage
\subsection{Sorting via direct selection}
\begin{description}
	\item[Short Description] Sorting via direct selection takes an unsorted sequence of data and sorts it by selecting the minimum value of the unsorted part of the data and adds it to the end of the already sorted part. This is done with the following steps:
	\begin{enumerate}
		\item At the beginning the data is unsorted, so find the minimum of the unsorted data.
		\item Swap the found minimum with the first element of the still unsorted part of the data, which is in the first step the first element of the data.
		\item Increase the pointer of the last element of the sorted data by one and search for the minimum of the remaining unsorted data.
		\item Swap the found minimum with the first element of the unsorted data. Continue with step 2).
	\end{enumerate}
	\item[Pseudocode] for $U := unsorted~data$:
	\begin{algorithm}
	\caption{Optimal Direct Selection Sort}
		\begin{algorithmic}[1]
		\Procedure{sortViaOptimalDirectSelection}{$U$}
			\If{$|U| = 0 \lor |U| = 1$} \State \Return \EndIf \State
			\For{$i \gets 0~\algorithmicto~|U|$}
				\State $swap(U[i], U[OptimalMinSearch(U,i,|U|)]$
			\EndFor
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\begin{algorithm}
	\caption{Non-optimal Direct Selection Sort}
		\begin{algorithmic}[1]
		\Procedure{sortViaNonOptimalDirectSelection}{$U$}
			\If{$|U| = 0 \lor |U| = 1$} \State \Return \EndIf \State
			\For{$i \gets |U|~\algorithmicto~0$}
				\State $swap(U[i], U[NonOptimalMinSearch(U,i,|U|)]$
			\EndFor
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\item[Example] The {\color{green}green} numbers are already sorted and the {\color{red}red} numbers will be swapped if necessary. \\[.5cm]
	\selectSortExample{Start:}{\color{red}4}{6}{3}{2}{\color{red}-1}{8}{fifth}{-1} \\
	\selectSortExample{1st step:}{\color{green}-1}{\color{red}6}{3}{\color{red}2}{4}{8}{fourth}{2} \\
	\selectSortExample{2nd step:}{\color{green}-1}{\color{green}2}{3}{6}{4}{8}{third}{3} \\
	\selectSortExample{3rd step:}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{red}6}{\color{red}4}{8}{fifth}{4} \\
	\selectSortExample{4th step:}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{green}4}{6}{8}{fifth}{6} \\
	\selectSortExample{5th step:}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{8}{sixth}{8} \\
	\selectSortExample{6th step:}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{\color{green}8}{sixth}{-} \\
	\vspace{3cm}
	\item[$O$-Notation]:
		\begin{table}[htdp]
		\caption{Direct Selection Complexity}
		\begin{tabular}{|c|c|c|} \hline
			Worst Case & Average Case & Best Case \\ \hline
			$O(n^2)$ & $O(n^2)$ & $O(n^2)$ \\ \hline
		\end{tabular}
		\label{default}
		\end{table}%
\end{description}

\newpage
\subsection{Sorting via direct insert}
\subsubsection{Without a \enquote{watcher-element}}
\begin{description}
	\item[Short Description] Sorting via direct insert takes an unsorted sequence of data and sorts it by selecting the first element of the unsorted part of the data and adds it to the right position of the already sorted part. The first step is always placing the minimum of the data at the first position. Every new element which has to be inserted at the right position is swapped through the already sorted data. \\ The algorithm perform the following steps:
	\begin{enumerate}
		\item Increase the pointer to the first element of the unsorted data by one and swap this element through until the right spot in the sorted data. 
		\item Do this until the pointer reaches the end of the data. Then the data is sorted.
	\end{enumerate}
	\item[Pseudocode] for $U := unsorted~data$:
	\begin{algorithm}
	\caption{Insert Sort}
		\begin{algorithmic}[1]
		\Procedure{sortViaDirectInsert}{$U$}
			\For{$i \gets 0~\algorithmicto~|U|$}
				\For{$j \gets i~\algorithmicto~j > 0 \land U[j-1] > U[j]$}
					\State $swap(U[j], U[j-1])$
				\EndFor
			\EndFor
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\item[Example] The {\color{green}green} numbers are already sorted and the {\color{red}red} numbers will be swapped to the right place. \\[.5cm]
		\insertSortExample{Start}{\color{green}4}{\color{red}6}{3}{2}{-1}{8}{second}{nElem=6} \\
		\insertSortExample{1st step (1)}{\color{green}4}{\color{green}6}{3}{2}{-1}{8}{third}{nElem=3} \\
		\insertSortExample{1st step (2)}{\color{green}4}{\color{red}3}{\color{green}6}{2}{-1}{8}{fourth}{nElem=2} \\
		\insertSortExample{1st step (3)}{\color{green}3}{\color{green}4}{\color{green}6}{2}{-1}{8}{fourth}{nElem=2} \\
		\insertSortExample{2nd step (1)}{\color{green}3}{\color{green}4}{\color{green}6}{\color{red}2}{-1}{8}{fourth}{nElem=2} \\
		\insertSortExample{2nd step (2)}{\color{green}3}{\color{green}4}{\color{red}2}{\color{green}6}{-1}{8}{fifth}{nElem=-1} \\
		\insertSortExample{2nd step (3)}{\color{green}3}{\color{red}2}{\color{green}4}{\color{green}6}{-1}{8}{fifth}{nElem=-1} \\
		\insertSortExample{2nd step (4)}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{-1}{8}{fifth}{nElem=-1} \\
		\insertSortExample{3rd step (1)}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{\color{red}-1}{8}{sixth}{nElem=8} \\
		\insertSortExample{3rd step (2)}{\color{green}2}{\color{green}3}{\color{green}4}{\color{red}-1}{\color{green}6}{8}{sixth}{nElem=8} \\
		\insertSortExample{3rd step (3)}{\color{green}2}{\color{green}3}{\color{red}-1}{\color{green}4}{\color{green}6}{8}{sixth}{nElem=8} \\
		\insertSortExample{3rd step (4)}{\color{green}2}{\color{red}-1}{\color{green}3}{\color{green}4}{\color{green}6}{8}{sixth}{nElem=8} \\
		\insertSortExample{3rd step (5)}{\color{green}1-}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{8}{sixth}{nElem=8} \\
		\insertSortExample{4th step (1)}{\color{green}1-}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{\color{red}8}{sixth}{nElem=} \\
		\insertSortExample{4th step (2)}{\color{green}1-}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{\color{green}8}{seventh}{nElem=-} \\
\end{description}
\subsubsection{With a \enquote{watcher-element}}
\begin{description}
	\item[Short Description] Sorting via direct insert with a \enquote{watcher-element} takes an unsorted sequence of data and sorts it by selecting the first element of the unsorted part of the data and adds it to the right position of the already sorted part. However as first step the minimum of the data is swapped with the element at the first position. This avoid the worst case of $O(n)$ swaps. Every new element which has to be inserted at the right position is swapped through the already sorted data. \\ The algorithm perform the following steps:
	\begin{enumerate}
		\item Find the minimum of the unsorted data.
		\item Swap the found minimum with the first element of the data to avoid the worst case of swapping through.
		\item Increase the pointer to the first element of the unsorted data by one and swap this element through until the right spot in the sorted data. Do this until the pointer reaches the end of the data. Then the data is sorted.
	\end{enumerate}
	\vspace{5cm}
	\item[Pseudocode] for $U := unsorted~data$, $s := lower~bound$ and $e := upper~bound$:
	\begin{algorithm}
	\caption{Insert Sort with watcher / guard element}
		\begin{algorithmic}[1]
		\Procedure{sortViaDirectInsertWithWatcher}{$U,s,e$}
			\If{$|U| = 0 \lor |U| = 1$} \State \Return \EndIf \State \State
			$swap(U[s], U[OptimalMinSearch(U,s,e)]$
			\For{$i \gets (s+2)~\algorithmicto~e$}
				\For{$j \gets i~\algorithmicto~U[j-1] > U[j]$}
					\State $swap(U[j], U[j-1])$
				\EndFor
			\EndFor
			\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\item[Example] The {\color{green}green} numbers are already sorted and the {\color{red}red} numbers will be swapped to the right place. \\[.5cm]
		\insertSortExample{Start}{\color{red}4}{6}{3}{2}{\color{red}-1}{8}{fifth}{min=-1} \\
		\insertSortExample{1st step (1)}{\color{green}-1}{\color{red}6}{3}{2}{4}{8}{second}{nElem=6} \\
		\insertSortExample{1st step (2)}{\color{green}-1}{\color{green}6}{3}{2}{4}{8}{third}{nElem=3} \\
		\insertSortExample{2nd step (1)}{\color{green}-1}{\color{green}6}{\color{red}3}{2}{4}{8}{fourth}{nElem=2} \\
		\insertSortExample{2nd step (2)}{\color{green}-1}{\color{red}3}{\color{green}6}{2}{4}{8}{fourth}{nElem=2} \\
		\insertSortExample{2nd step (3)}{\color{green}-1}{\color{green}3}{\color{green}6}{2}{4}{8}{fourth}{nElem=2} \\
		\insertSortExample{3rd step (1)}{\color{green}-1}{\color{green}3}{\color{green}6}{\color{red}2}{4}{8}{fifth}{nElem=4} \\
		\insertSortExample{3rd step (2)}{\color{green}-1}{\color{green}3}{\color{red}2}{\color{green}6}{4}{8}{fifth}{nElem=4} \\
		\insertSortExample{3rd step (3)}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{green}6}{\color{red}4}{8}{fifth}{nElem=4} \\
		\insertSortExample{4th step (1)}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{red}4}{\color{green}6}{8}{sixth}{nElem=8} \\
		\insertSortExample{5th step (1)}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{\color{red}8}{seventh}{nElem=-} \\
		\insertSortExample{5th step (2)}{\color{green}-1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}6}{\color{green}8}{seventh}{nElem=-} \\
	\item[$O$-Notation]:
		\begin{table}[htdp]
		\caption{Direct Insert Complexity}
		\begin{tabular}{|c|c|c|} \hline
			Worst Case & Average Case & Best Case \\ \hline
			$O(n^2)$ & $O(n^2)$ & $O(n)$ \\ \hline
		\end{tabular}
		\label{defaulttt}
		\end{table}%
\end{description}

\newpage
\subsection{Mergesort}
\subsubsection{The \texttt{Merge}-Function}
\begin{description}
	\item[Short Description] The \texttt{Merge}-Function is used in the later described Natural- and Bottom-Up-Mergesort. It's preconditions are that the given part of the array to merge has to be sorted from the index \texttt{lo} to \texttt{m-1} and from \texttt{m} to \texttt{hi}. Both border indexes are inclusive! So \texttt{m} denotes the middle boundary. After the merge the part of the array from \texttt{lo} to \texttt{hi} is sorted.
		\begin{enumerate}
			\item Check if the indexes are in range
			\item Return if the array has a size $\leq 1$
			\item Check if the array is sorted from \texttt{lo} to \texttt{m-1} and from \texttt{m} to \texttt{hi}, otherwise abort
			\item Order the array into a tmp-array in bitonic format. This means \textit{ASC} from \texttt{lo} to \texttt{m-1} and \textit{DESC} from \texttt{m} to \texttt{hi}
			\item Merge the tmp-array into the array starting with two pointers, one from the head and the other one from the tail. The array is merge when the pointers cross.
		\end{enumerate}
	\newpage
	\item[Pseudocode] for $U := unsorted~data$, $T := tmp~storage$, $lo := lower~bound$, $m := middle$, $hi :=upper~bound$, $iSd := is~second~part~descending~sorted$, $wD := write~descending~back$:
	\begin{algorithm}
	\caption{Merge Part 1 - Write into $T$}
		\begin{algorithmic}[1]
		\Require $(U[lo]~\algorithmicto~U[m] \to ASC \land U[m]~\algorithmicto~U[hi] \to DESC) \lor (U[lo]~\algorithmicto~U[hi] \to ASC)$
		\Procedure{merge}{$U,T,lo,m,hi, iSd, wD$}
			\If{isSecondSubsequenceDescending}\Comment{already bitonic presorted}
				\For{$i \gets lo~\algorithmicto~hi$} \State T[i] = U[i] \EndFor
			\Else\Comment{both subsequences are ascedending sorted}
				\For{$i \gets lo~\algorithmicto~m$} \State T[i] = U[i] \EndFor
				\For{$i \gets m \land k \gets hi~\algorithmicto~hi$} \State T[i] = U[k] \EndFor
			\EndIf
		\algstore{mergebreak}	
		\end{algorithmic}
	\end{algorithm}	
	\begin{algorithm}
	\caption{Merge Part 2 - Write back to $U$}
		\begin{algorithmic}[1]	
		\algrestore{mergebreak}
			\State $rdIdxLo \gets lo \land rdIdxHi \gets hi$
			\If{writeBackDesceding}
				\State $wIdx \gets (hi-1)$
			\Else
				\State $wIdx \gets lo$
			\EndIf
			\While{$rdIdxLo<rdIdxHi$} 
				\If{$T[readIdxLo] < T[rdIdxHi]$}
					\State $U[writeIdx] = T[readIdxLo] \land readIdxLo \gets readIdxLo+1$
				\Else
					\State $U[writeIdx] = T[readIdxHi] \land readIdxHi \gets readIdxHi-1$
				\EndIf
				\If{writeBackDesceding}
					\State $writeIdx \gets writeIdx-1$
				\Else
					\State $writeIdx \gets wIdx+1$
				\EndIf
			\EndWhile
		\EndProcedure
		\end{algorithmic}
	\end{algorithm}
	\item[Example] The {\color{blue}blue} number is the middle, the {\color{red}red} numbers will be selected and the {\color{green}green} numbers are sorted \\[.5cm]
		\mergeExampleSorted{unmerged}{-1}{3}{6}{\color{blue}1}{2}{8}{first} \\
		\mergeExampleTmp{tmp}{-1}{3}{6}{8}{2}{1}{first}{sixth} \\
		\mergeExampleTmp{1st step (tmp)}{\color{red}-1}{3}{6}{8}{2}{1}{first}{sixth} \mergeExampleSorted{merged}{-1}{-}{-}{-}{-}{-}{first} \\
		\mergeExampleTmp{2nd step (tmp)}{-1}{3}{6}{8}{2}{\color{red}1}{second}{sixth} \mergeExampleSorted{merged}{-1}{1}{-}{-}{-}{-}{second} \\
		\mergeExampleTmp{3rd step (tmp)}{-1}{3}{6}{8}{\color{red}2}{1}{second}{fifth} \mergeExampleSorted{merged}{-1}{1}{2}{-}{-}{-}{third} \\
		\mergeExampleTmp{4th step (tmp)}{-1}{\color{red}3}{6}{8}{2}{1}{second}{fourth} \mergeExampleSorted{merged}{-1}{1}{2}{3}{-}{-}{fourth} \\
		\mergeExampleTmp{5th step (tmp)}{-1}{3}{\color{red}6}{8}{2}{1}{third}{fourth} \mergeExampleSorted{merged}{-1}{1}{2}{3}{6}{-}{fifth} \\
		\mergeExampleTmp{6th step (tmp)}{-1}{3}{6}{\color{red}8}{2}{1}{fourth}{fourth} \mergeExampleSorted{merged}{-1}{1}{2}{3}{6}{8}{sixth} \\
\end{description}

\subsubsection{Natural Mergesort}
\begin{description}
	\item[Short Description] The natural Mergesort is an iterative alternative of the Mergesort-procedure. The fundamental idea is taking advantage of already existing sorted parts in the data. By using these naturally pre-sorted parts, merge-steps can be spared. Those pre-sorted parts are called \enquote{bitonic runs}. Those bitonic runs is first ordered ascending and the descending. It can also be sorted only ascending or descending but not first descending and then ascending. It is implemented in the following steps:
		\begin{enumerate}
			\item Find pre-sorted bitonic sequences in data and store boundaries of the sequences. If the dat a is already sorted ascending only two boundaries are found, otherwise always 3 or more.
			\item Merge pair of sequences by writing the second sequences back in descending order.
			\item Reduce the boundaries until there are only two left, then the data is sorted.
		\end{enumerate}
	\newpage
	\item[Pseudocode] for $U := unsorted~data$:
	\begin{algorithm}
	\caption{Natural Mergesort}
		\begin{algorithmic}[1]
		\Procedure{sortViaNaturalMergeSort}{$U$}
			\State $I := idxOfBitonicRuns(U)$
			\State $writeDesc := false$
			\State $T := tmp~storage$
			\While{$|I| > 2$}
				\State $lo \gets pop(I) \land m \gets pop(I) \land hi \gets pop(I)$ 
				\State $merge(U, T, lo, m, hi, \algorithmicTrue, writeDesc)$
				\State $I := reduceIdxOfBitonicRuns(U)$
				\State $writeDesc \gets \neg writeDesc$
			\EndWhile	
		\EndProcedure
		\end{algorithmic}
	\end{algorithm}	
	\item[Example] The {\color{blue}blue} and {\color{red}red} colored numbers represent the pre-sorted parts of the data and in the following step the blue part will be merged with its following red part. The {\color{green}green} numbers are sorted \\[.5cm] 
		\mergeSortsExample{unsorted}{-1}{1}{2}{1}{3}{2}{10}{5} \\
		\mergeSortsExample{1st step: boundaries}{\color{blue}-1}{\color{blue}1}{\color{blue}2}{\color{red}1}{\color{red}3}{\color{blue}2}{\color{blue}10}{\color{red}5} \\
		\mergeSortsExample{2nd step: merge}{\color{blue}-1}{\color{blue}1}{\color{blue}1}{\color{blue}2}{\color{blue}3}{\color{red}2}{\color{red}5}{\color{red}10} \\
		\mergeSortsExample{3rd step: merge}{\color{green}-1}{\color{green}1}{\color{green}1}{\color{green}2}{\color{green}2}{\color{green}3}{\color{green}5}{\color{green}10} \\
	\item[$O$-Notation]:
		\begin{table}[htdp]
		\caption{Natural-Mergesort Complexity}
		\begin{tabular}{|c|c|c|} \hline
			Worst Case & Average Case & Best Case \\ \hline
			$O(n*log_2~n)$ & $O(n*log_2~n)$ & $O(n*log_2~n)$ \\ \hline
		\end{tabular}
		\label{defaulttt}
		\end{table}%
\end{description}

\newpage
\subsubsection{Bottom-Up Mergesort}
\begin{description}
	\item[Short Description] The Bottom-Up Mergesort is an iterative alternative of the Mergesort-procedure. The fundamental idea is to start from the bottom by merging all pairs, then in the next rounds the double size, so 4 and so on. So in each rounds the doubled amount of items is merged. Example:
		\begin{itemize}
			\item indexes of Round 1: 0,1, 2,3, 4,5 \ldots
			\item indexes of Round 2: 0,3, 4,7, 8,11 \ldots
			\item indexes of Round 3: 0,7, 8,15, 16,23 \ldots
			\item \ldots
			\item indexes of last Round: 0, SIZE-1 			
		\end{itemize}
As shown in the example it is implemented in the following steps:
		\begin{enumerate}
			\item Merge all pairs, starting from index 0
			\item Merge all doubles pairs, starting from index 0 and so on until the last index equals SIZE-1
		\end{enumerate}
	\item[Pseudocode] for $U := unsorted~data$:
	\begin{algorithm}
	\caption{Bottom-Up Mergesort}
		\begin{algorithmic}[1]
		\Procedure{sortViaBottomUpMergeSort}{$U$}
			\State $r := |U| / 2$
			\If{$|U| \bmod 2 \neq 0$}\Comment{increase rounds}
				\State $r \gets r + 1$ 
			\EndIf
			\State $T := tmp~storage$
			\For{$lo \gets 0~\algorithmicto~r$}\Comment{merge from the bottom}
				\State $m \gets lo+2^{r-1} \land hi \gets lo+2^{r}$
				\State $merge(U, T, lo, m, hi, \algorithmicFalse, \algorithmicFalse)$
			\EndFor
		\EndProcedure
		\end{algorithmic}
	\end{algorithm}	
	\newpage
	\item[Example] The {\color{blue}blue} and {\color{red}red} colored numbers represent the pre-sorted parts of the data and in the following step the blue part will be merged with its following red part. The {\color{green}green} numbers are sorted \\[.5cm]
		\mergeSortsExample{unsorted}{-1}{1}{2}{1}{3}{2}{10}{5} \\
		\mergeSortsExample{1st step: merge}{\color{blue}-1}{\color{blue}10}{\color{red}1}{\color{red}7}{\color{blue}2}{\color{blue}8}{\color{red}5}{\color{red}10} \\
		\mergeSortsExample{2nd step: merge}{\color{blue}-1}{\color{blue}1}{\color{blue}7}{\color{blue}12}{\color{red}2}{\color{red}5}{\color{red}8}{\color{red}10} \\
		\mergeSortsExample{3rd step: merge}{\color{green}-1}{\color{green}1}{\color{green}2}{\color{green}5}{\color{green}7}{\color{green}8}{\color{green}10}{\color{green}12} \\
	\item[$O$-Notation]:
		\begin{table}[htdp]
		\caption{Bottom-Up-Mergesort Complexity}
		\begin{tabular}{|c|c|c|} \hline
			Worst Case & Average Case & Best Case \\ \hline
			$O(n*log_2~n)$ & $O(n*log_2~n)$ & $O(n*log_2~n)$ \\ \hline
		\end{tabular}
		\label{defaulttt}
		\end{table}%
\end{description}

\newpage
\subsection{3-way-partitioning Quicksort}
\begin{description}
	\item[Short Description] The 3-way-partitioning Quicksort also orders the elements which are equal to the Pivot-element in the middle of the to-sorting data.
It is implemented in the following steps:
		\begin{enumerate}
			\item Choose the element in the middle as pivot and move it to the right end.
			\item Find an element on the left side of the pivot which is greater than the pivot and one on the right side which is smaller. Swap these two elements if the pointers haven't crossed.
			\item If an element on the left or right side of the pivot is equal to the pivot move it the left or right end respectively. 
			\item Continue swapping and moving equal elements until the pointers starting from left and right cross.
			\item Bring the pivots from the left and right end to the middle.
			\item Perform two recursive Quicksorts: one from the left end until the beginning of the pivot brought into the middle before and the other one from the right end of the pivot in the middle until the right outer end.
		\end{enumerate}
	\newpage
	\item[Pseudocode] for $U := unsorted~data$, $left := U[head]$, $right := U[tail]$
	\begin{algorithm}
	\caption{3-way-partitioning QuickSort}
		\begin{algorithmic}[1]
		\Procedure{sortVia3WayPartitioningQuicksort}{$U, left, right$}
			\State swap middle element to the right and make it the $Pivot$
			\If{$left \leq right$} \State \Return \EndIf
			\Repeat
				\State find element $< Pivot$ starting from $left$
				\State find element $> Pivot$ starting from $right$
				\If{element = $Pivot$}
					\State swap $\to$ left or right end respectively
				\EndIf
			\Until{pointers cross $\lor$ $left$ end is reached}
			\State bring $Pivot$ from right end to the middle
			\State swap elements = $Pivot$ to the middle
			\Statex
			\State $lEnd \gets$ left end $\land~rEnd \gets$ right end of elements = $Pivot$ 
			\Statex
			\State sortVia3WayPartitioningQuicksort($U, left, lEnd$)
			\State sortVia3WayPartitioningQuicksort($U, right, rEnd$)
		\EndProcedure
		\end{algorithmic}
	\end{algorithm}	
	\item[Example] The {\color{red}red} numbers will be swapped,  {\color{blue}blue} numbers are the one for the next recursion. The {\color{green}green} numbers are sorted \\[.5cm]
		\quicksortsExample{pivot to right end}{1}{5}{7}{\color{red}4}{3}{4}{9}{\color{red}2} \\
		\quicksortsExample{1st step (1)}{1}{\color{red}5}{7}{2}{3}{\color{red}4}{9}{4} \\
		\quicksortsExample{1st step (2)}{\color{red}1}{\color{red}4}{7}{2}{3}{5}{9}{4} \\
		\quicksortsExample{2nd step (1)}{4}{1}{\color{red}7}{2}{\color{red}3}{5}{9}{4} \\
		\quicksortsExample{3rd step (1)}{4}{1}{3}{2}{\color{red}7}{5}{9}{\color{red}4} \\
		\quicksortsExample{3rd step (2)}{\color{red}4}{1}{3}{\color{red}2}{4}{5}{9}{7} \\
		\quicksortsExample{3rd step (3)}{\color{blue}2}{\color{blue}1}{\color{blue}3}{\color{green}4}{\color{green}4}{5}{9}{7} \\
		\quicksortsExample{4th step (1)}{2}{\color{red}1}{\color{red}3}{\color{green}4}{\color{green}4}{5}{9}{7} \\
		\quicksortsExample{4th step (2)}{\color{red}2}{3}{\color{red}1}{\color{green}4}{\color{green}4}{5}{9}{7} \\
		\quicksortsExample{4th step (2)}{1}{\color{blue}3}{\color{blue}2}{\color{green}4}{\color{green}4}{5}{9}{7} \\
		\quicksortsExample{5th step (1)}{1}{\color{red}3}{\color{red}2}{\color{green}4}{\color{green}4}{5}{9}{7} \\
		\quicksortsExample{5th step (2)}{\color{green}1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}4}{\color{blue}5}{\color{blue}9}{\color{blue}7} \\
		\quicksortsExample{6th step (1)}{\color{green}1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}4}{5}{\color{red}9}{\color{red}7} \\
		\quicksortsExample{6th step (2)}{\color{green}1}{\color{green}2}{\color{green}3}{\color{green}4}{\color{green}4}{5}{\color{green}7}{\color{green}9} \\
	\item[$O$-Notation]:
		\begin{table}[htdp]
		\caption{3-way-partitioning Quicksort Complexity}
		\begin{tabular}{|c|c|c|} \hline
			Worst Case & Average Case & Best Case \\ \hline
			$O(n*log_2~n)$ & $O(n*log_2~n)$ & $O(n * log_2~n)$
		\end{tabular}
		\label{defaulttt}
		\end{table}%
\end{description}

\newpage
\subsection{3-way-partitioning Quicksort with hybridization}
\begin{description}
	\item[Short Description] The hybrid Quicksort is a variation of the Quicksort avoiding special cases. These are
	\begin{enumerate}
		\item limiting recursion depth and performing an Insertsort instead
		\item performing a merge step on heavily unequal sizes of partial Quicksorts
	\end{enumerate}
Otherwise the previously mentioned 3-way-partitioning Quicksort is performed. Additionally to make it hybrid the following steps are added:
		\begin{enumerate}
			\item If the amount of elements to sort is smaller or equal than 25, an InsertSort is used
			\item If the case occurs that before the next recursion of the Quicksort starts one half contains 10 times the amount of the other half the next recursion step is performed by diving the remaining data in the middle. To adjust this change a \texttt{merge}-step is performed after the recursion.
		\end{enumerate}
	\item[Pseudocode] for $U := unsorted~data$, $left := U[head]$, $right := U[tail]$
	\begin{algorithm}
	\caption{Hybrid 3-way-partitioning QuickSort}
		\begin{algorithmic}[1]
		\Procedure{sortViaHybrid3WayPartitioningQuicksort}{$U, left, right$}
			\If{$right - left < 25$}
				\State sortViaDirectInsertWithWatcher($U,left,right$)
			\Else
				\State \ldots
				\State sortVia3WayPartitioningQuicksort as above
				\State \ldots
				\If{the subsequence of one recursive call is $10\times$ bigger than the other}
					\State sortVia3WayPartitioningQuicksort($U, left, mid$)
					\State sortVia3WayPartitioningQuicksort($U, mid, right$)
					\State merge($U, T, left, mid, right, \algorithmicFalse, \algorithmicFalse$)
				\Else
					\State sortVia3WayPartitioningQuicksort($U, left, lEnd$)
					\State sortVia3WayPartitioningQuicksort($U, right, rEnd$)			
				\EndIf
			\EndIf
		\EndProcedure
		\end{algorithmic}
	\end{algorithm}	
	\newpage
	\item[Example] The example is for showing how the worst case in Quicksort is handled. As a matter of space the worst case in this example is if the size of elements in one recursion is 6-times bigger than the other one. \\ The {\color{red}red} numbers will be swapped,  {\color{blue}blue} numbers are the one for the next recursion. The {\color{green}green} numbers are sorted \\[.5cm]
	\quicksortsExample{pivot to right end}{1}{4}{5}{\color{red}7}{6}{9}{3}{\color{red}3} \\
	\quicksortsExample{1st step (1)}{1}{4}{5}{3}{6}{\color{red}9}{\color{red}3}{7} \\
	\quicksortsExample{1st step (2)}{1}{4}{5}{3}{6}{3}{\color{red}9}{\color{red}7} \\
	\quicksortsExample{worst case}{\color{blue}1}{\color{blue}4}{\color{blue}5}{\color{blue}3}{\color{blue}6}{\color{blue}3}{7}{9} \\
	\quicksortsExample{correction}{\color{blue}1}{\color{blue}4}{\color{blue}5}{\color{blue}3}{6}{3}{7}{9} \\
	\quicksortsExample{2nd step (1)}{1}{\color{red}4}{5}{\color{red}3}{6}{3}{7}{9} \\
	\quicksortsExample{2nd step (2)}{1}{3}{\color{red}5}{\color{red}4}{6}{3}{7}{9} \\
	\quicksortsExample{2nd step (3)}{\color{blue}1}{\color{blue}3}{4}{5}{6}{3}{7}{9} \\
	\quicksortsExample{right recursion}{1}{3}{4}{5}{\color{blue}6}{\color{blue}3}{\color{blue}7}{\color{blue}9} \\
	\quicksortsExample{3rd step (1)}{1}{3}{4}{5}{6}{\color{red}3}{7}{\color{red}9} \\
	\quicksortsExample{3rd step (2)}{1}{3}{4}{5}{\color{red}6}{9}{7}{\color{red}3} \\
	\quicksortsExample{right recursion)}{1}{3}{4}{5}{3}{\color{blue}9}{\color{blue}7}{\color{blue}6} \\
	\quicksortsExample{4th step (1)}{1}{3}{4}{5}{3}{9}{\color{red}7}{\color{red}6} \\
	\quicksortsExample{4th step (2)}{1}{3}{4}{5}{3}{\color{red}9}{\color{red}6}{7} \\
	\quicksortsExample{next recursion}{1}{3}{4}{5}{3}{6}{\color{blue}9}{\color{blue}7} \\
	\quicksortsExample{5th step (1)}{1}{3}{4}{5}{3}{6}{\color{red}9}{\color{red}7} \\
	\quicksortsExample{merge halves}{\color{blue}1}{\color{blue}3}{\color{blue}4}{\color{blue}5}{3}{6}{7}{9} \\
	\quicksortsExample{done}{\color{green}1}{\color{green}3}{\color{green}3}{\color{green}4}{\color{green}5}{\color{green}6}{\color{green}7}{\color{green}9} \\
	\item[$O$-Notation]:
		\begin{table}[htdp]
		\caption{Hybrid Quicksort Complexity}
		\begin{tabular}{|c|c|c|} \hline
			Worst Case & Average Case & Best Case \\ \hline
			$O(n*log_2~n)$ & $O(n*log_2~n)$ & $O(n * log_2~n)$ \\ \hline
		\end{tabular}
		\label{defaulttt}
		\end{table}%
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Setup}
%
% here will be the environment details: cLion, gTest, C++14
% OS, Language and IDE, Compiler + flags, code examples
% automated tests, no warnings
%
\subsection{Used Frameworks}
The only framework which was used is the Google Test Framework \textbf{gtest}\footnote{\url{https://github.com/google/googletest}}. It was compiled and added as a shared library to the project. 

\subsection{Preconditions}
The following preconditions were given by the professor:
\begin{enumerate}
	\item Programming language: C++ with the latest standard 14
	\item Compiler flags: -03 -g0 -Wall
	\item No warning on compilation
	\item Sorting algorithms have to work with \texttt{integer}, \texttt{double} and \texttt{std::string}
	\item For each sorting algorithm test should be written with the gTest library
	\item A separate project for time measuring has to be set up with the compiler flags mentioned above. The condition are:
	\begin{itemize}
		\item Before each test the cache has to be emptied by filling an array with 20MB of data.
		\item Time measurement with data initialized with random, ascending and descending sorted values to point out the best, worst and average case.
		\item The amount of data to be sorted shall increase from 8KB\footnote{kilo bytes = $10^3$ bytes} over 8MB\footnote{mega bytes = $10^6$ bytes} up to 8GB\footnote{giga bytes = $10^9$ bytes} in step of multiplying by 2. Hence the sizes of the data are: 8KB, 16KB, 32KB, 64KB, 128KB, 256KB, 512MB, 1MB, 2MB, 4MB, 8MB, 16MB, 32MB, 64MB, 128MB, 256MB, 512MB, 1GB, 2GB and 4GB. Exceptions are the sorting by direct insert and direct select which have $O(n^2)$ in almost every case. These test cases are limited to 8MB.
	\end{itemize}
\end{enumerate}

\subsection{Realization}
With the given preconditions the exercise was realized with
\begin{itemize}
	\item The cLion IDE\footnote{\url{https://www.jetbrains.com/clion/}}, for platform independent compilation with \texttt{cmake}
	\item On a Macbook Pro 13-inch, Early 2011, OS Version 10.11) with 1 processor and 2 cores
	\begin{itemize}
		\item L2-Cache: 256KB per core $\Rightarrow$ 512KB in total
		\item L3-Cache: 3MB
		\item Main memory: 8 GB
	\end{itemize}
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Execution}
This section describes how the execution was implemented. 

First the algorithm were implemented in a generic manner with template methods to make certain parts reusable. This can also be seen in the code snippets in the previous section. For each function separate tests were written to ensure their correct behavior. In total 32 tests were written and the project was continuously refactored. In general the project was implemented in a test-driven approach and documented in detail in the source files. This will be explained in detain in the first subsection.

As the time measuring should be implemented with no debug information, a separate project was set up with an appropriate time measuring environment. The flags for optimization were used as well to gain the maximum performance. This will be explained in detain in the second subsection.

%
% show tests, random generators, helpers
%
\subsection{Test project with gTest}
The test project to verify the correctness of the implemented sort algorithms was realized with the gTest library from Google. Self-written tests were demanded. 

Several helpers for generating test values and verifies the data structures after sorting were implemented a better structure of the tests. For the generation of the random \texttt{double} values, the algorithm of Mersenne-Twister\footnote{\url{http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/ARTICLES/mt.pdf}} between \texttt{INT\_MIN and INT\_MAX} is used.
%
% time measuring, data types, amount of data, empty cache before each run
%
\subsection{Time measuring with chronos}
As already pointed out in the introduction of parent section, a separate project for time measuring is implemented with the desired compiler flags \texttt{-g0 -03 -Wall}. 

For each size all possible combinations will be executed and results printed on the command line. Smart pointers were used all along, so it was not necessary to worry about memory management.

%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\section{Results}
In this section the results of time measuring are printed as tables. For each algorithm an interpretation of the results is provided below the table.
%
% no graphics just tables!
%
%\subsection{Sorting via direct selection}
\begin{table}[htdp]
	\caption{Direct Select Sort with \textbf{optimal} minimum search - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n^2)$} & \parbox[c]{3.5cm}{Random \\$O(n^2)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n^2)$} \\ \hline
		1KB & 125 & 0,016 & 0,014 & 0,017 \\ \hline
		2KB & 250 & 0,048 & 0,052 & 0,053 \\ \hline
		4KB & 500 & 0,181 & 0,178 & 0,235 \\ \hline
		8KB & 1.000 & 0,641 & 0,596 & 0,823 \\ \hline
		16KB & 2.000 & 2,291 & 2,493 & 3,005 \\ \hline
		32KB & 4.000 & 9,084 & 9,371 & 13,712 \\ \hline
		64KB & 8.000 & 40,584 & 37,784 & 50,264 \\ \hline
		128KB & 16.000 & 155,631 & 155,512 & 202,348 \\ \hline
		256KB & 32.000 & 611,356 & 617,521 & 791,066 \\ \hline
		512KB & 64.000 & 2.424,382 & 2.453,179 & 3.461,468 \\ \hline
		1MB & 128.000 & 9.566,811 & 9.558,843 & 12.602,158 \\ \hline
		2MB & 256.000 & 36.461,074 & 36.491,507 & 48.849,572 \\ \hline
		4MB & 512.000 & 166.127,555 & 173.156,363 & 161.061,041 \\ \hline
		8MB & 1024.000 & 334.343,525 & 345.234,344 & 311.123,422 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage
\begin{table}[htdp]
	\caption{Direct Select Sort with \textbf{non-optimal} minimum search - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n^2)$} & \parbox[c]{3.5cm}{Random \\$O(n^2)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n^2)$} \\ \hline
		1KB & 125 & 0,125 & 0,02 & 0,064 \\ \hline
		2KB & 250 & 0,066 & 0,063 & 0,062 \\ \hline
		4KB & 500 & 0,274 & 0,266 & 0,245 \\ \hline
		8KB & 1.000 & 1,049 & 0,974 & 1,069 \\ \hline
		16KB & 2.000 & 4,169 & 3,986 & 4,169 \\ \hline
		32KB & 4.000 & 15,831 & 21,279 & 16,934 \\ \hline
		64KB & 8.000 & 72,091 & 66,212 & 65,211 \\ \hline
		128KB & 16.000 & 268,842 & 261,759 & 280,641 \\ \hline
		256KB & 32.000 & 1.086,531 & 1.068,409 & 1.058,501 \\ \hline
		512KB & 64.000 & 4.297,342 & 4.364,332 & 4.328,582 \\ \hline
		1MB & 128.000 & 16.805,246 & 16.687,005 & 16.780,907 \\ \hline
		2MB & 256.000 & 66.570,907 & 68.659,897 & 65.869,297 \\ \hline
		4MB & 512.000 & 280.506,942 & 283.446,342 & 286.403,731 \\ \hline
		8MB & 1024.000 & 1.376.546,922 & 1.234.522,634 & 1.304.234,563 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage
\begin{table}[htdp]
	\caption{Direct Insert Sort \textbf{with watcher} element - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n^2)$} & \parbox[c]{3.5cm}{Random \\$O(n^2)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n)$} \\ \hline
		1KB & 125 & 0,007 & 0,006 & 0,001 \\ \hline
		2KB & 250 & 0,022 & 0,031 & 0,001 \\ \hline
		4KB & 500 & 0,063 & 0,066 & 0,002 \\ \hline
		8KB & 1.000 & 0,236 & 0,776 & 0,004 \\ \hline
		16KB & 2.000 & 0,939 & 0,858 & 0,007 \\ \hline
		32KB & 4.000 & 4,381 & 3,38 & 0,015 \\ \hline
		64KB & 8.000 & 14,764 & 21,074 & 0,026 \\ \hline
		128KB & 16.000 & 67,552 & 68,247 & 0,049 \\ \hline
		256KB & 32.000 & 260,046 & 272,692 & 0,106 \\ \hline
		512KB & 64.000 & 1.174,881 & 1.159,717 & 0,235 \\ \hline
		1MB & 128.000 & 4.384,383 & 4.326,191 & 0,403 \\ \hline
		2MB & 256.000 & 16.852,195 & 16.912,54 & 0,761 \\ \hline
		4MB & 512.000 & 85.522,896 & 82.136,826 & 1,679 \\ \hline
		8MB & 1024.000 & 325.343,342 & 321.643,234 & 3,023 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\begin{table}[htdp]
	\caption{Direct Insert Sort \textbf{without watcher} element - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n^2)$} & \parbox[c]{3.5cm}{Random \\$O(n^2)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n)$} \\ \hline
		1KB & 125 & 0,007 & 0,009 & 0,001 \\ \hline
		2KB & 250 & 0,025 & 0,022 & 0,002 \\ \hline
		4KB & 500 & 0,076 & 0,073 & 0,003 \\ \hline
		8KB & 1.000 & 0,494 & 0,289 & 0,002 \\ \hline
		16KB & 2.000 & 1,196 & 1,121 & 0,004 \\ \hline
		32KB & 4.000 & 5,623 & 6,257 & 0,012 \\ \hline
		64KB & 8.000 & 17,646 & 21,789 & 0,017 \\ \hline
		128KB & 16.000 & 77,259 & 79,857 & 0,027 \\ \hline
		256KB & 32.000 & 311,725 & 316,534 & 0,052 \\ \hline
		512KB & 64.000 & 1.334,022 & 1.265,534 & 0,091 \\ \hline
		1MB & 128.000 &  4.957,583 & 4.839,884 & 0,193 \\ \hline
		2MB & 256.000 & 18.777,582 & 18.909,018 & 0,347 \\ \hline
		4MB & 512.000 & 91.881,412 & 89.775,988 & 0,761 \\ \hline
		8MB & 1024.000 & 378.124,435 & 365.244,156 & 1,434 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage
\begin{table}[htdp]
	\caption{\textbf{Natural} Mergesort - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n*log_2~n)$} & \parbox[c]{3.5cm}{Random \\$O(n*log_2~n)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n*log_2~n)$} \\ \hline
		1KB & 125 & 0,052 & 0,018 & 0,006 \\ \hline
		2KB & 250 & 0,072 & 0,026 & 0,006 \\ \hline
		4KB & 500 & 0,062 & 0,179 & 0,009 \\ \hline
		8KB & 1.000 & 0,104 & 0,104 & 0,012 \\ \hline
		16KB & 2.000 & 0,241 & 0,197 & 0,013 \\ \hline
		32KB & 4.000 & 0,399 & 0,442 & 0,038 \\ \hline
		64KB & 8.000 & 0,998 & 0,814 & 0,029 \\ \hline
		128KB & 16.000 & 1,611 & 1,683 & 0,043 \\ \hline
		256KB & 32.000 & 3,716 & 3,386 & 0,094 \\ \hline
		512KB & 64.000 & 7,699 & 7,285 & 0,148 \\ \hline
		1MB & 128.000 & 19,881 & 18,131 & 0,275 \\ \hline
		2MB & 256.000 & 36,052 & 36,961 & 0,529 \\ \hline
		4MB & 512.000 & 86,411 & 84,735 & 1,035 \\ \hline
		8MB & 1024.000 & 168,453 & 166,228 & 3,788 \\ \hline
		16MB & 2048.000 & 337,754 & 323,207 & 8,285 \\ \hline
		32MB & 4096.000 & 711,816 & 708,413 & 14,636 \\ \hline
		64MB & 8192.000 & 1.452,511 & 1.432,902 & 30,129 \\ \hline
		128MB & 16.386.000 & 3.039,709 & 3.014,209 & 67,624 \\ \hline
		256MB & 32.768.000 & 6.321,147 & 6.350,046 & 154,709 \\ \hline
		512MB & 65.536.000 & 13.039,986 & 13.009,507 & 320,525 \\ \hline
		1GB & 131.072.000 & 26.866,826 & 26.755,499 & 679,786 \\ \hline
		2GB & 262.144.000 & 52.662,634 & 59.174,127 & 1.436,505 \\ \hline
		4GB & 524.288.000 & 9.785.859,935 & 6.271.623,593 & 3.926,895 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage
\begin{table}[htdp]
	\caption{\textbf{Bottom-up} Mergesort - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n*log_2~n)$} & \parbox[c]{3.5cm}{Random \\$O(n*log_2~n)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n*log_2~n)$} \\ \hline	
		1KB & 125 & 0,044 & 0,047 & 0,02 \\ \hline
		2KB & 250 & 0,051 & 0,035 & 0,038 \\ \hline
		4KB & 500 & 0,089 & 0,077 & 0,141 \\ \hline
		8KB & 1.000 & 0,197 & 0,138 & 0,171 \\ \hline
		16KB & 2,000 & 0,338 & 0,303 & 0,308 \\ \hline
		32KB & 4.000 & 0,629 & 0,612 & 0,672 \\ \hline
		64KB & 8.000 & 0,861 & 0,924 & 0,446 \\ \hline
		128KB & 16.000 & 1,955 & 1,827 & 0,929 \\ \hline
		256KB & 32.000& 3,971 & 3,997 & 1,952 \\ \hline
		512KB & 64.000 & 9,597 & 9,627 & 4,126 \\ \hline
		1MB & 128.000 & 18,046 & 17,678 & 9,767 \\ \hline
		2MB & 256.000 & 39,095 & 39,290 & 19,236 \\ \hline
		4MB & 512.000 & 83,000 & 83,000 & 41,000 \\ \hline
		8MB & 1024.000 & 172,000 & 174,000 & 87,770 \\ \hline
		16MB & 2048.000 & 383,000 & 361,000 & 180,000 \\ \hline
		32MB & 4096.000 & 766,000 & 754,000 & 381,000 \\ \hline
		64MB & 8192.000 & 1.641,000 & 1.658,000 & 847,000 \\ \hline
		128MB & 16.386.000 & 3.304,314 & 3.342,386 & 1.629,869 \\ \hline
		256MB & 32.768.000 & 6.939,091 & 6.969,053 & 3.434,097 \\ \hline
		512MB & 65.536.000 & 14.943,215 & 16.344,875 & 7315,546 \\ \hline
		1GB & 131.072.000 & 30.463,418 & 30.378,241 & 15.083,457 \\ \hline
		2GB & 262.144.000 & 64.691,651 & 64.807,992 & 31.273,719 \\ \hline
		4GB & 524.288.000 & 2.929.851,036 & 2.735.258,633 & 544.107,184 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage
\begin{table}[htdp]
	\caption{Quicksort with \textbf{three-way-partitioning} - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n*log_2~n)$} & \parbox[c]{3.5cm}{Random \\$O(n*log_2~n)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n*log_2~n)$} \\ \hline
		1KB & 125 & 0,008 & 0,007 & 0,003 \\ \hline
		2KB & 250 & 0,031 & 0,015 & 0,005 \\ \hline
		4KB & 500 & 0,033 & 0,033 & 0,009 \\ \hline
		8KB & 1.000 & 0,071 & 0,099 & 0,017 \\ \hline
		16KB & 2.000 & 0,145 & 0,313 & 0,034 \\ \hline
		32KB & 4.000 & 0,285 & 0,308 & 0,125 \\ \hline
		64KB & 8.000 & 0,557 & 0,601 & 0,144 \\ \hline
		128KB & 16.000 & 1,207 & 1,261 & 0,270 \\ \hline
		256KB & 32.000& 2,718 & 2,643 & 0,691 \\ \hline
		512KB & 64.000 & 5,475 & 9,919 & 1,933 \\ \hline
		1MB & 128.000 & 12,990 & 11,501 & 2,593 \\ \hline
		2MB & 256.000 & 23,610 & 23,631 & 5,438 \\ \hline
		4MB & 512.000 & 50,000 & 50,000 & 11,000 \\ \hline
		8MB & 1024.000 & 104,000 & 105,000 & 30,920 \\ \hline
		16MB & 2048.000 & 221,000 & 215,000 & 49,072 \\ \hline
		32MB & 4096.000 & 481,000 & 461,000 & 102,228 \\ \hline
		64MB & 8192.000 & 989,000 & 988,000 & 214,053 \\ \hline
		128MB & 16.386.000 & 2.042,638 & 2.040,686 & 450,071 \\ \hline
		256MB & 32.768.000 & 4.233,067 & 4.167,985 & 950,415 \\ \hline
		512MB & 65.536.000 & 8.964,916 & 8.928,053 & 2.062,972 \\ \hline
		1GB & 131.072.000 & 18.383,604 & 18.484,818 & 4.169,181 \\ \hline
		2GB & 262.144.000 & 39.167,371 & 39.258,816 & 9.035,457 \\ \hline
		4GB & 524.288.000 & 82.576,764 & 82.608,998 & 18.382,807 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage
\begin{table}[htdp]
	\caption{Quicksort with \textbf{three-way-partitioning} with \textbf{hybridization} - Results in $milliseconds$}
	\begin{tabular}{|r|c|r|r|r|} \hline
		Size of data & Loop rounds & \parbox[c]{3.5cm}{Descending \\ $O(n*log_2n~)$} & \parbox[c]{3.5cm}{Random \\$O(n*log_2~n)$} & \parbox[c]{3.5cm}{Ascending \\ $O(n*log_2~n)$} \\ \hline
		1KB & 125 & 0,011 & 0,009 & 0,007 \\ \hline
		2KB & 250 & 0,021 & 0,017 & 0,015 \\ \hline
		4KB & 500 & 0,038 & 0,038 & 0,025 \\ \hline
		8KB & 1.000 & 0,097 & 0,081 & 0,056 \\ \hline
		16KB & 2.000 & 0,181 & 0,185 & 0,118 \\ \hline
		32KB & 4.000 & 0,389 & 0,399 & 0,231 \\ \hline
		64KB & 8.000 & 1,054 & 0,771 & 0,681 \\ \hline
		128KB & 16.000 & 1,695 & 2,464 & 1,263 \\ \hline
		256KB & 32.000 & 4,532 & 4,251 & 2,584 \\ \hline
		512KB & 64.000 & 13,871 & 7,758 & 6,621 \\ \hline
		1MB & 128.000 & 23,513 & 27,788 & 11,465 \\ \hline
		2MB & 256.000 & 42,318 & 37,374 & 24,622 \\ \hline
		4MB & 512.000 & 83,036 & 90,031 & 55,382 \\ \hline
		8MB & 1.024.000 & 181,075 & 171,421 & 119,021 \\ \hline
		16MB & 2.048.000 & 364,449 & 351,072 & 263,007 \\ \hline
		32MB & 4.096,000 & 772,836 & 761,957 & 576,457 \\ \hline
		64MB & 8.192.000 & 1.594,031 & 1.594,732 & 1.147,487 \\ \hline
		128MB & 16.386.000 & 3.393,994 & 3.266,566 & 2.450,899 \\ \hline
		256MB & 32.768.000 & 7.137,769 & 7.206,703 & 5.268,502 \\ \hline
		512MB & 65.536.000 & 14.712,446 & 14.980,232 & 10.920,068 \\ \hline
		1GB & 131.072.000 & 30.422,156 & 30.405,184 & 22.491,865 \\ \hline
		2GB & 262.144.000 & 63.929,184 & 63.738,425 & 47.088,279 \\ \hline
		4GB & 524.288.000 & 175.348,961 & 177.230,619 & 138.253,538 \\ \hline
	\end{tabular}
	\label{default}
\end{table}%
\clearpage


%%%%%%%%%%%%%%%%%%%%%%%%
\section{Summary}
%
% sum up the results for O(n) algorithm in comparison with the n^2 ones ... maybe
%
\textbf{SelectSort} behaved as expected with $O(n^2)$ in all three cases. This means that for the double amount of data the amount of time needed raised by the factor 4. The non-optimal version with searching the minimum from the end to the beginning of the data structure took about 50\% more time than the optimal version.

\textbf{InsertSort} behaved as expected with $O(n^2)$ for descending and random order, but only $O(n)$ linear time in the ascending case. The version with a watcher/guard element was about 10\% faster than the version without it. In both implementations the search for the minimum was optimal.

\textbf{Bottom-Up-MergeSort} and \textbf{Natural-MergeSort}  behaved with $O(n*log_2~n)$ in every case, but Natural-MergeSort is about 10\% faster than the Bottom-Up version. Natural-MergeSort should be as equally fast in the ascending and descending case, but the ascending case needs no copying into a temporal storage before the function for the determination of the indexes of the bitonic runs avoids it and hence its faster. Due to the need of additional space both sort algorithms grow exponentially when reaching the limit of memory available. Here its 4GB, when a certain amount of data has to be swapped to hard disc.

\textbf{3-way-partitioning QuickSort} and \textbf{3-way-partitioning QuickSort with hybridization} behaved with $O(n*log_2~n)$ in every case, but the version with hybridization is about 30\% slower than the version without it. Because there is no need of additional space both sort algorithms perform very well when reaching the limit of memory available.

\end{document}  